{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import Levenshtein\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "import torchinfo\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dataloader import AudioDataset, AudioDatasetTest\n",
    "from model import Network\n",
    "from model import ASRMODEL\n",
    "from train_test import train_model, validate_model, decode_prediction, calculate_levenshtein, save_model, load_model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMUdict_ARPAbet = {\n",
    "    \"\" : \" \",\n",
    "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\", \n",
    "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\", \n",
    "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\", \n",
    "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\", \n",
    "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\", \n",
    "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\", \n",
    "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\", \n",
    "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
    "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
    "}\n",
    "\n",
    "CMUdict = list(CMUdict_ARPAbet.keys())\n",
    "ARPAbet = list(CMUdict_ARPAbet.values())\n",
    "\n",
    "\n",
    "PHONEMES = CMUdict[:-2]  #Changed this from [:-2]\n",
    "LABELS = ARPAbet[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 64,\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 10,\n",
    "    'checkpoint_path': '/home/ubuntu/ASRMODEL/checkpoint.pth',\n",
    "    'best_model_path': '/home/ubuntu/ASRMODEL/best_model.pth',\n",
    "    'optimizer': 'AdamW',\n",
    "    'beam_width': 3,\n",
    "    'test_beam_width': 10, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dataloader \n",
    "train_dataset = AudioDataset(PHONEMES, partition='train-clean-100')\n",
    "dev_dataset = AudioDataset(PHONEMES, partition='dev-clean')\n",
    "test_dataset = AudioDatasetTest(PHONEMES, partition='test-clean')\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing code to check if your data loaders are working\n",
    "for data in train_loader:\n",
    "    x, y, lx, ly = data\n",
    "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size,input_channels, kernel_size,  output_channels,  embed_size= 192, output_size= 41, training=True\n",
    "model= ASRMODEL(input_channels=27,output_channels=256,embed_size=256, kernel_size=3, training=False)\n",
    "model.to(device=device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(\n",
    "    model, \n",
    "    input_data=[x.to(device), lx]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "criterion = torch.nn.CTCLoss()\n",
    "decoders   = CTCBeamDecoder(labels=LABELS, blank_id=0, beam_width=100, log_probs_input=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project='ASR', \n",
    "                 reinit=True,\n",
    "                #  id = '',\n",
    "                #  resume='must',\n",
    "                 project_name='ASR', \n",
    "                 config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lev_dist = 'inf'\n",
    "for epoch in range(config['epochs']):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        curr_lr = param_group['lr']\n",
    "        print(f'Current learning rate: {curr_lr}')\n",
    "    \n",
    "    \n",
    "    print(\"Start Train \\t{}\".format(epoch))\n",
    "    startTime = time.time()\n",
    "    train_loss, train_lev_dist = train_model(model, train_loader, criterion, scaler, optimizer, decoders, phoneme_map= LABELS)\n",
    "    print(\"Start Dev \\t{}\".format(epoch))\n",
    "    valid_loss, valid_dist = validate_model(model =model, val_loader= dev_loader, decoder =decoders, criterion = criterion, phoneme_map = LABELS)\n",
    "    print('***Saving Checkpoint ***')\n",
    "    save_model(model, optimizer, epoch, train_loss, valid_loss, config['checkpoint_path'])\n",
    "    # Print the metrics\n",
    "    print(\"Train Levenshtein distance {:.04f}\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_lev_dist,train_loss, curr_lr))\n",
    "    print(\"\\tVal Dist {:.04f}%\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n",
    "    scheduler.step(valid_dist)\n",
    "    \n",
    "    # Log metrics to Wandb\n",
    "    wandb.log({\n",
    "        'train_loss': train_loss,  \n",
    "        'valid_dist': valid_dist, \n",
    "        'valid_loss': valid_loss, \n",
    "        'lr'        : curr_lr\n",
    "    })\n",
    "    \n",
    "    wandb.save(config['checkpoint_path'])\n",
    "    \n",
    "    \n",
    "    if valid_dist <= best_lev_dist:\n",
    "        best_valid_dist = valid_dist\n",
    "        save_model(model, optimizer, epoch, train_loss, valid_loss, config['best_model_path'])\n",
    "        wandb.save(config['best_model_path'])\n",
    "        print('***Saving Best Model***')\n",
    "        \n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BEAM_WIDTH = config['test_beam_width']\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "print(\"Start Test\")\n",
    "for data in tqdm(test_loader):\n",
    "    x, lx = data\n",
    "    x     = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        h, lh = model(x, lx)\n",
    "    \n",
    "    pred_strings = decode_prediction(h, lh, decoders, PHONEMES)\n",
    "    results.extend(pred_strings)\n",
    "    \n",
    "    del x, lx, h, lh\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['Predicted'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
